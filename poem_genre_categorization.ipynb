{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poem Genres Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data as pandas dataframe\n",
    "data = pd.read_csv('Poems.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why didst thou promise such a beauteous day,\\r...</td>\n",
       "      <td>Nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The welcome Sun from sea Freake is returned,\\r...</td>\n",
       "      <td>Nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I met a courtier riding on the plain,\\r\\nWell-...</td>\n",
       "      <td>Nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Walking the fields a wantcatcher I spied,\\r\\nT...</td>\n",
       "      <td>Nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fishing, if I a fisher may protest,\\r\\nOf plea...</td>\n",
       "      <td>Nature</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content    type\n",
       "0  Why didst thou promise such a beauteous day,\\r...  Nature\n",
       "1  The welcome Sun from sea Freake is returned,\\r...  Nature\n",
       "2  I met a courtier riding on the plain,\\r\\nWell-...  Nature\n",
       "3  Walking the fields a wantcatcher I spied,\\r\\nT...  Nature\n",
       "4  Fishing, if I a fisher may protest,\\r\\nOf plea...  Nature"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 748 entries, 0 to 747\n",
      "Data columns (total 2 columns):\n",
      "content    748 non-null object\n",
      "type       748 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 17.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the dataset\n",
    "data = data.sample(frac=1,random_state=10).reset_index().drop(columns = [\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nature', 'sad', 'Love', 'peace'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the dependant variable\n",
    "y = data.type\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "container = []\n",
    "for i in range(748):\n",
    "    poem = re.sub('[^a-zA-Z]',' ',data['content'][i])  # Converting all the irrelevent characters into space\n",
    "    poem = poem.lower() # converting all the alphabets into lowercase\n",
    "    poem = poem.split() # tokenizing the string into words\n",
    "    ps = PorterStemmer() # Defining Stemmer tool \n",
    "    poem = [ps.stem(word) for word in poem if not word in set(stopwords.words('english'))] # Removing all the stopwords and lemmatizing all the relevent words\n",
    "    poem = \" \".join(poem) \n",
    "    container.append(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(container,y,test_size = 0.2, random_state = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all the tokens into features for modeling\n",
    "count_train = cv.fit_transform(X_train)\n",
    "count_test = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 1 - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining naive bayes classifier\n",
    "nb_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68\n",
      "[[56 11  0  1]\n",
      " [12 20  0  6]\n",
      " [ 5  0  3  8]\n",
      " [ 4  0  1 23]]\n"
     ]
    }
   ],
   "source": [
    "# fitting the model on the training set and predicting the outcome of the test set\n",
    "nb_classifier.fit(count_train,y_train)\n",
    "pred = nb_classifier.predict(count_test)\n",
    "\n",
    "# computing the accuracy of the model\n",
    "score = metrics.accuracy_score(y_test,pred)\n",
    "print(score)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test,pred,labels = ['Love', 'Nature', 'peace', 'sad'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By looking over the model score we can say that our model is 68% accurate while predicting the genres but we could increase it by adjusting the value of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.0\n",
      "Score:  0.6733333333333333\n",
      "\n",
      "Alpha:  0.01\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.02\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.03\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.04\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.05\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.06\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.07\n",
      "Score:  0.74\n",
      "\n",
      "Alpha:  0.08\n",
      "Score:  0.74\n",
      "\n",
      "Alpha:  0.09\n",
      "Score:  0.74\n",
      "\n",
      "Alpha:  0.1\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.11\n",
      "Score:  0.7266666666666667\n",
      "\n",
      "Alpha:  0.12\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.13\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.14\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.15\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.16\n",
      "Score:  0.7266666666666667\n",
      "\n",
      "Alpha:  0.17\n",
      "Score:  0.7266666666666667\n",
      "\n",
      "Alpha:  0.18\n",
      "Score:  0.7266666666666667\n",
      "\n",
      "Alpha:  0.19\n",
      "Score:  0.7266666666666667\n",
      "\n",
      "Alpha:  0.2\n",
      "Score:  0.7266666666666667\n",
      "\n",
      "Alpha:  0.21\n",
      "Score:  0.7266666666666667\n",
      "\n",
      "Alpha:  0.22\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.23\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.24\n",
      "Score:  0.74\n",
      "\n",
      "Alpha:  0.25\n",
      "Score:  0.74\n",
      "\n",
      "Alpha:  0.26\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.27\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.28\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.29\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.3\n",
      "Score:  0.7333333333333333\n",
      "\n",
      "Alpha:  0.31\n",
      "Score:  0.7266666666666667\n",
      "\n",
      "Alpha:  0.32\n",
      "Score:  0.72\n",
      "\n",
      "Alpha:  0.33\n",
      "Score:  0.72\n",
      "\n",
      "Alpha:  0.34\n",
      "Score:  0.7266666666666667\n",
      "\n",
      "Alpha:  0.35000000000000003\n",
      "Score:  0.7133333333333334\n",
      "\n",
      "Alpha:  0.36\n",
      "Score:  0.7133333333333334\n",
      "\n",
      "Alpha:  0.37\n",
      "Score:  0.7133333333333334\n",
      "\n",
      "Alpha:  0.38\n",
      "Score:  0.7133333333333334\n",
      "\n",
      "Alpha:  0.39\n",
      "Score:  0.7066666666666667\n",
      "\n",
      "Alpha:  0.4\n",
      "Score:  0.7066666666666667\n",
      "\n",
      "Alpha:  0.41000000000000003\n",
      "Score: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shantanu\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.7066666666666667\n",
      "\n",
      "Alpha:  0.42\n",
      "Score:  0.7066666666666667\n",
      "\n",
      "Alpha:  0.43\n",
      "Score:  0.7066666666666667\n",
      "\n",
      "Alpha:  0.44\n",
      "Score:  0.7066666666666667\n",
      "\n",
      "Alpha:  0.45\n",
      "Score:  0.7066666666666667\n",
      "\n",
      "Alpha:  0.46\n",
      "Score:  0.7066666666666667\n",
      "\n",
      "Alpha:  0.47000000000000003\n",
      "Score:  0.7066666666666667\n",
      "\n",
      "Alpha:  0.48\n",
      "Score:  0.7066666666666667\n",
      "\n",
      "Alpha:  0.49\n",
      "Score:  0.7066666666666667\n",
      "\n",
      "Alpha:  0.5\n",
      "Score:  0.7066666666666667\n",
      "\n",
      "Alpha:  0.51\n",
      "Score:  0.7066666666666667\n",
      "\n",
      "Alpha:  0.52\n",
      "Score:  0.7066666666666667\n",
      "\n",
      "Alpha:  0.53\n",
      "Score:  0.7066666666666667\n",
      "\n",
      "Alpha:  0.54\n",
      "Score:  0.7\n",
      "\n",
      "Alpha:  0.55\n",
      "Score:  0.7\n",
      "\n",
      "Alpha:  0.56\n",
      "Score:  0.7\n",
      "\n",
      "Alpha:  0.5700000000000001\n",
      "Score:  0.7\n",
      "\n",
      "Alpha:  0.58\n",
      "Score:  0.7\n",
      "\n",
      "Alpha:  0.59\n",
      "Score:  0.7\n",
      "\n",
      "Alpha:  0.6\n",
      "Score:  0.7\n",
      "\n",
      "Alpha:  0.61\n",
      "Score:  0.7\n",
      "\n",
      "Alpha:  0.62\n",
      "Score:  0.7\n",
      "\n",
      "Alpha:  0.63\n",
      "Score:  0.7\n",
      "\n",
      "Alpha:  0.64\n",
      "Score:  0.7\n",
      "\n",
      "Alpha:  0.65\n",
      "Score:  0.7\n",
      "\n",
      "Alpha:  0.66\n",
      "Score:  0.7\n",
      "\n",
      "Alpha:  0.67\n",
      "Score:  0.7\n",
      "\n",
      "Alpha:  0.68\n",
      "Score:  0.7\n",
      "\n",
      "Alpha:  0.6900000000000001\n",
      "Score:  0.7\n",
      "\n",
      "Alpha:  0.7000000000000001\n",
      "Score:  0.7\n",
      "\n",
      "Alpha:  0.71\n",
      "Score:  0.6933333333333334\n",
      "\n",
      "Alpha:  0.72\n",
      "Score:  0.6933333333333334\n",
      "\n",
      "Alpha:  0.73\n",
      "Score:  0.6933333333333334\n",
      "\n",
      "Alpha:  0.74\n",
      "Score:  0.6933333333333334\n",
      "\n",
      "Alpha:  0.75\n",
      "Score:  0.6933333333333334\n",
      "\n",
      "Alpha:  0.76\n",
      "Score:  0.6866666666666666\n",
      "\n",
      "Alpha:  0.77\n",
      "Score:  0.6866666666666666\n",
      "\n",
      "Alpha:  0.78\n",
      "Score:  0.6866666666666666\n",
      "\n",
      "Alpha:  0.79\n",
      "Score:  0.68\n",
      "\n",
      "Alpha:  0.8\n",
      "Score:  0.6866666666666666\n",
      "\n",
      "Alpha:  0.81\n",
      "Score:  0.6866666666666666\n",
      "\n",
      "Alpha:  0.8200000000000001\n",
      "Score:  0.6866666666666666\n",
      "\n",
      "Alpha:  0.8300000000000001\n",
      "Score:  0.6866666666666666\n",
      "\n",
      "Alpha:  0.84\n",
      "Score:  0.6866666666666666\n",
      "\n",
      "Alpha:  0.85\n",
      "Score:  0.6866666666666666\n",
      "\n",
      "Alpha:  0.86\n",
      "Score:  0.6866666666666666\n",
      "\n",
      "Alpha:  0.87\n",
      "Score:  0.6866666666666666\n",
      "\n",
      "Alpha:  0.88\n",
      "Score:  0.6866666666666666\n",
      "\n",
      "Alpha:  0.89\n",
      "Score:  0.6866666666666666\n",
      "\n",
      "Alpha:  0.9\n",
      "Score:  0.6866666666666666\n",
      "\n",
      "Alpha:  0.91\n",
      "Score:  0.6866666666666666\n",
      "\n",
      "Alpha:  0.92\n",
      "Score:  0.68\n",
      "\n",
      "Alpha:  0.93\n",
      "Score:  0.68\n",
      "\n",
      "Alpha:  0.9400000000000001\n",
      "Score:  0.68\n",
      "\n",
      "Alpha:  0.9500000000000001\n",
      "Score:  0.68\n",
      "\n",
      "Alpha:  0.96\n",
      "Score:  0.68\n",
      "\n",
      "Alpha:  0.97\n",
      "Score:  0.68\n",
      "\n",
      "Alpha:  0.98\n",
      "Score:  0.68\n",
      "\n",
      "Alpha:  0.99\n",
      "Score:  0.68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicting the outcome on each value of alpha from 0 to 1 with a step size of 0.01\n",
    "\n",
    "def train_and_predict(alpha):\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    nb_classifier.fit(count_train,y_train)\n",
    "    pred = nb_classifier.predict(count_test)\n",
    "    score = metrics.accuracy_score(y_test,pred)\n",
    "    return score\n",
    "\n",
    "alphas = np.arange(0,1,0.01)\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alpha))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By observing the scores over various alphas, It can be concluded that if we choose alpha = 0.07 then our model becomes 74% accurate while predicting the genres of the poems which is a good improvement in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, I am going to try a different approach of modeling with cross validation and hyper-parameter tuning. Hoping, My model may perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining independent variables set\n",
    "X1 = cv.fit_transform(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the value of alpha as a parameter-grid\n",
    "alpha = np.arange(0,1,0.01)\n",
    "param_grid = {'alpha':alpha}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining naive bayes classifier\n",
    "nb_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining grid search object with naive bayes classifier and 10-fold cross validation\n",
    "nb_classifier_cv = GridSearchCV(nb_classifier, param_grid, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shantanu\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "C:\\Users\\Shantanu\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "C:\\Users\\Shantanu\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "C:\\Users\\Shantanu\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "C:\\Users\\Shantanu\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "C:\\Users\\Shantanu\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "C:\\Users\\Shantanu\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "C:\\Users\\Shantanu\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "C:\\Users\\Shantanu\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "C:\\Users\\Shantanu\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "C:\\Users\\Shantanu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'alpha': array([0.  , 0.01, ..., 0.98, 0.99])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model with cross validation\n",
    "nb_classifier_cv.fit(X1,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.35000000000000003}\n",
      "0.6911764705882353\n"
     ]
    }
   ],
   "source": [
    "print(nb_classifier_cv.best_params_)\n",
    "print(nb_classifier_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By this approach the accuracy of our model comes out to be approx 70% and with previous method model accuracy is 74%, so our average model accuracy is about 72% ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 2 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the classifier \n",
    "rf_classifier = RandomForestClassifier(n_estimators = 300, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the classifier into the training set\n",
    "rf_classifier.fit(count_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the outcomes on the test set\n",
    "pred1 = rf_classifier.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64\n",
      "[[57 11  0  0]\n",
      " [14 20  0  4]\n",
      " [ 9  0  3  4]\n",
      " [11  1  0 16]]\n"
     ]
    }
   ],
   "source": [
    "# computing the accuracy of the model\n",
    "score = metrics.accuracy_score(y_test,pred1)\n",
    "print(score)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test,pred1,labels = ['Love', 'Nature', 'peace', 'sad'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The accuracy of the Random Forest model is 64% which quite low as compared to the Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
